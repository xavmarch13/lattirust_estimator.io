<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/lattirust_estimator.io/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=lattirust_estimator.io/livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="
  How to solve SVP ?
  #

The way we solve the Shortest Vector Problem (SVP) and similar problems depends significantly on the lattice dimension. In lower dimensions, exact solvers are practical, and there are two main approaches: enumeration and sieving. Both methods perform an exhaustive search over all short lattice vectors—enumeration does this deterministically, while sieving is typically randomized. However, as the lattice dimension grows, the number of possible solutions increases exponentially, making these methods infeasible for high dimensions (think 100 and more).">
<meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
<meta name="theme-color" media="(prefers-color-scheme: dark)" content="#343a40">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/lattirust_estimator.io/docs/lattice-reduction/">
  <meta property="og:site_name" content="Lattirust estimator 0.1">
  <meta property="og:title" content="Lattice reduction">
  <meta property="og:description" content="How to solve SVP ? # The way we solve the Shortest Vector Problem (SVP) and similar problems depends significantly on the lattice dimension. In lower dimensions, exact solvers are practical, and there are two main approaches: enumeration and sieving. Both methods perform an exhaustive search over all short lattice vectors—enumeration does this deterministically, while sieving is typically randomized. However, as the lattice dimension grows, the number of possible solutions increases exponentially, making these methods infeasible for high dimensions (think 100 and more).">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="website">
<title>Lattice reduction | Lattirust estimator 0.1</title>
<link rel="icon" href="/lattirust_estimator.io/favicon.png" >
<link rel="manifest" href="/lattirust_estimator.io/manifest.json">
<link rel="canonical" href="http://localhost:1313/lattirust_estimator.io/docs/lattice-reduction/">
<link rel="stylesheet" href="/lattirust_estimator.io/book.min.6c8b9d2a1fc95075ed7da46ca81060b39add8fff6741ac51259f768929281e2c.css" integrity="sha256-bIudKh/JUHXtfaRsqBBgs5rdj/9nQaxRJZ92iSkoHiw=" crossorigin="anonymous">
  <script defer src="/lattirust_estimator.io/fuse.min.js"></script>
  <script defer src="/lattirust_estimator.io/en.search.min.ab710d7184d1da92e9afe7f84b054dc9aa5f56c2674c8fba3136865ef46f391d.js" integrity="sha256-q3ENcYTR2pLpr&#43;f4SwVNyapfVsJnTI&#43;6MTaGXvRvOR0=" crossorigin="anonymous"></script>
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/lattirust_estimator.io/docs/lattice-reduction/index.xml" title="Lattirust estimator 0.1" />
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>


<link rel="stylesheet" type="text/css" href="http://localhost:1313/lattirust_estimator.io/scss/hugo-simplecite.min.138dd14c6aaf1b1a9b55c4fe22f82166812ce8081413d67a3b464e411d2b63ef.css">
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/lattirust_estimator.io/"><span>Lattirust estimator 0.1</span>
  </a>
</h2>


<div class="book-search hidden">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>
<script>document.querySelector(".book-search").classList.remove("hidden")</script>















  
  <ul>
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/introduction/" class="">Introduction</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/preliminaries/" class="">Preliminaries</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/cost-models/" class="">Cost Models</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/lattice-reduction/" class="active">Lattice reduction</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/sis/" class="">SIS</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/rsis-msis/" class="">Module SIS and Ring SIS</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/sis-variants/" class="">SIS variants</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/lattirust_estimator.io/docs/estimator-options/" class="">Estimator options and API</a>
  

          
  <ul>
    
  </ul>

        </li>
      
    
  </ul>














</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/lattirust_estimator.io/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <h3>Lattice reduction</h3>

  <label for="toc-control">
    
    <img src="/lattirust_estimator.io/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#lattice-reduction">Lattice reduction</a>
      <ul>
        <li><a href="#key-lattice-reduction-algorithms">Key Lattice Reduction Algorithms</a></li>
        <li><a href="#cost-considerations">Cost Considerations</a></li>
        <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization</a></li>
        <li><a href="#root-hermite-factor">Root hermite factor</a></li>
        <li><a href="#geometric-series-assumption-gsa">Geometric Series Assumption (GSA)</a></li>
      </ul>
    </li>
    <li><a href="#lll-algorithm">LLL algorithm</a>
      <ul>
        <li><a href="#cost-of-lll">Cost of LLL</a></li>
      </ul>
    </li>
    <li><a href="#bkz-algorithm">BKZ algorithm</a>
      <ul>
        <li><a href="#hkz-reduction">HKZ reduction</a></li>
        <li><a href="#bkz">BKZ</a></li>
        <li><a href="#cost-of-bkz">Cost of BKZ</a></li>
      </ul>
    </li>
    <li><a href="#refinements">Refinements</a>
      <ul>
        <li><a href="#the-first-gsa-lie">The first GSA lie</a></li>
        <li><a href="#the-second-gsa-lie-and-ztgsa">The second GSA lie and Z(T)GSA</a></li>
        <li><a href="#bkz-20-improvements">BKZ 2.0 improvements</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown book-article"><h1 id="how-to-solve-svp-">
  How to solve SVP ?
  <a class="anchor" href="#how-to-solve-svp-">#</a>
</h1>
<p>The way we solve the Shortest Vector Problem (SVP) and similar problems depends significantly on the lattice dimension. In lower dimensions, exact solvers are practical, and there are two main approaches: <tag><strong>enumeration and sieving</strong></tag>. Both methods perform an exhaustive search over all short lattice vectors—enumeration does this deterministically, while sieving is typically randomized. However, as the lattice dimension grows, the number of possible solutions increases exponentially, making these methods infeasible for high dimensions (think 100 and more).</p>
<p>In higher dimensions, we rely on <strong>approximation algorithms</strong>, better known as lattice reduction algorithms. These algorithms don’t find the exact solution but instead provide an approximation where the vector length is upper bounded by a function of the dimension. Lattice reduction can be thought of as the algorithmic equivalent of inequalities like <strong>Hermite’s</strong> and <strong>Mordell’s</strong> [<a id="cite-1" class="hugo-simplecite-cite-hyperlink" href="#bibreference-1" title="P. Nguyen, Hermite’s constant and lattice algorithms, in The LLL algorithm: Survey and applications, Springer, 2009, pp. 19–69.">1</a>], which bound the shortest vector length in theoretical terms.</p>
<ul>
<li>Hermite&rsquo;s inequality: $$\forall d \geq 2: \gamma_d \leq \left(\sqrt{\frac{4}{3}}\right)^{d-1}$$</li>
<li>Mordell&rsquo;s inequality: $$\forall d,k \text{ such that } 2\leq k \leq d: \gamma_d \leq \sqrt{\gamma_k}^{\frac{d-1}{k-1}}$$</li>
</ul>
<p>In practice, both exact and approximate solvers are used together. Exact solvers usually start with a preprocessing step using lattice reduction to simplify the problem. On the other hand, lattice reduction algorithms often call exact solvers as subroutines, using them multiple times during their process. This section focuses on explaining the cost of approximation algorithms such as LLL and BKZ as a whole, and we will refer to the cost of the exact SVP solver used as a subroutine as the &ldquo;cost models,&rdquo; described in the next section.</p>
<h2 id="lattice-reduction">
  Lattice reduction
  <a class="anchor" href="#lattice-reduction">#</a>
</h2>
<p><em>Lattice reduction algorithms</em> are designed to transform a given basis of a lattice into a &ldquo;reduced&rdquo; basis, where the vectors are shorter and closer to being orthogonal. While a lattice does not generally have an orthogonal basis (unlike in Euclidean space), the goal of lattice reduction is to produce a basis that approximates orthogonality as closely as possible. This transformation simplifies solving challenging lattice problems such as the Shortest Vector Problem (SVP).</p>
<p>This section is based on the works of [<a id="cite-1" class="hugo-simplecite-cite-hyperlink" href="#bibreference-1" title="P. Nguyen, Hermite’s constant and lattice algorithms, in The LLL algorithm: Survey and applications, Springer, 2009, pp. 19–69.">1</a>], [<a id="cite-2" class="hugo-simplecite-cite-hyperlink" href="#bibreference-2" title="P. Nguyen and B. Vallee, The LLL algorithm. Springer, 2010. ">2</a>], [<a id="cite-3" class="hugo-simplecite-cite-hyperlink" href="#bibreference-3" title="Y. Chen and P. Nguyen, BKZ 2.0: Better lattice security estimates, In Proc. International conference on the theory and application of cryptology and information security, 2011, pp. 1–20. ">3</a>], [<a id="cite-4" class="hugo-simplecite-cite-hyperlink" href="#bibreference-4" title="N. Gama, N. Howgrave-Graham, H. Koy, and P. Nguyen, Rankin’s constant and blockwise lattice reduction, In Proc. Advances in cryptology-CRYPTO 2006: 26th annual international cryptology conference, santa barbara, california, USA, august 20-24, 2006. Proceedings 26, 2006, pp. 112–130. ">4</a>], [<a id="cite-5" class="hugo-simplecite-cite-hyperlink" href="#bibreference-5" title="A. Lenstra, H. Lenstra, and L. Lovász, Factoring polynomials with rational coefficients, Mathematische annalen, vol. 261, pp. 515–534, 1982. ">5</a>], [<a id="cite-6" class="hugo-simplecite-cite-hyperlink" href="#bibreference-6" title="M. Albrecht and L. Ducas, Lattice attacks on NTRU and LWE: A history of refinements, Cryptology ePrint Archive, 2021. ">6</a>], and [<a id="cite-7" class="hugo-simplecite-cite-hyperlink" href="#bibreference-7" title="N. Gama and P. Nguyen, Predicting lattice reduction, In Proc. Advances in cryptology–EUROCRYPT 2008: 27th annual international conference on the theory and applications of cryptographic techniques, istanbul, turkey, april 13-17, 2008. Proceedings 27, 2008, pp. 31–51. ">7</a>].</p>
<figure style="text-align: center; margin: 1em auto; max-width: 100%;">
    <img src="lattice_orthogonal.png" alt="Depiction of a closer to orthogonal basis" style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px;">
    
        
            <figcaption style="font-size: 0.9em; margin-top: 0.5em; font-style: italic; text-align: center; color: #555;">
                Two different bases, one being close to orthogonal.
            </figcaption>
        
    
</figure>
<h3 id="key-lattice-reduction-algorithms">
  Key Lattice Reduction Algorithms
  <a class="anchor" href="#key-lattice-reduction-algorithms">#</a>
</h3>
<ul>
<li><strong>LLL Algorithm (Lenstra–Lenstra–Lovász)</strong>: This algorithm produces a reduced basis in polynomial time. The resulting basis vectors are guaranteed to be within a known factor of the shortest vector, although the algorithm does not necessarily find the shortest vector itself [<a id="cite-5" class="hugo-simplecite-cite-hyperlink" href="#bibreference-5" title="A. Lenstra, H. Lenstra, and L. Lovász, Factoring polynomials with rational coefficients, Mathematische annalen, vol. 261, pp. 515–534, 1982. ">5</a>].</li>
<li><strong>BKZ Algorithm (Block Korkine-Zolotarev)</strong>: A more advanced generalization of the LLL algorithm that provides stronger reductions at the cost of increased computational complexity. The BKZ algorithm divides the lattice into overlapping blocks and applies LLL reduction within each block, achieving more accurate approximations of the shortest vector [<a id="cite-4" class="hugo-simplecite-cite-hyperlink" href="#bibreference-4" title="N. Gama, N. Howgrave-Graham, H. Koy, and P. Nguyen, Rankin’s constant and blockwise lattice reduction, In Proc. Advances in cryptology-CRYPTO 2006: 26th annual international cryptology conference, santa barbara, california, USA, august 20-24, 2006. Proceedings 26, 2006, pp. 112–130. ">4</a>].</li>
</ul>
<h3 id="cost-considerations">
  Cost Considerations
  <a class="anchor" href="#cost-considerations">#</a>
</h3>
<p>Both LLL and BKZ make iterative local improvements to a basis by using an exact SVP solver (often referred to as an SVP oracle). Therefore, the overall cost of the algorithm can be divided into two components:</p>
<ol>
<li><strong>Local cost</strong>: The computational cost associated with solving the SVP within each block.</li>
<li><strong>Global cost</strong>: The number of times the algorithm needs to invoke the SVP oracle during the entire basis reduction process.</li>
</ol>
<p>Together, these components determine the total cost of performing lattice reduction.</p>
<h3 id="gram-schmidt-orthogonalization">
  Gram-Schmidt Orthogonalization
  <a class="anchor" href="#gram-schmidt-orthogonalization">#</a>
</h3>
<p>Gram-Schmidt orthogonalization is a method for orthonormalizing a set of vectors in an inner product space, most commonly the Euclidean space $\mathbb{R}^n$. The process transforms a set of linearly independent vectors into an orthogonal set of vectors that spans the same subspace.</p>
<p>Given a set of linearly independent vectors ${\mathbf{b}_1, \mathbf{b}_2, \ldots, \mathbf{b}_n}$, the Gram-Schmidt process produces an orthogonal set ${\mathbf{b}^{*}_1, \ldots, \mathbf{b}^*_n}$ as follows:</p>
<ol>
<li>$\mathbf{b}_1^* = \mathbf{b}_1$</li>
<li>For $i = 2$ to $n$:
$$
   \mathbf{b}_i^* = \mathbf{b}_i - \sum_{j=1}^{i-1} \text{proj}_{\mathbf{b}_j^*}(\mathbf{b}_i)
   $$
where $\text{proj}_{\mathbf{b}_j^{*}}(\mathbf{b}_i)$ is the projection of $\mathbf{b}_i$ onto $\mathbf{b}_j^*$, given by:
$$
   \text{proj}_{\mathbf{b}_j^*}(\mathbf{b}_i) = \frac{\langle \mathbf{b}_i, \mathbf{b}_j^* \rangle}{\langle \mathbf{b}_j^*, \mathbf{b}_j^* \rangle} \mathbf{b}_j^*.
   $$</li>
</ol>
<p>Gram-Schmidt orthogonalization is widely used in lattice reduction because it allows the basis to be triangularized. More precisely, it transforms the basis into the following form:</p>
$$
\begin{pmatrix}
\|\mathbf{b}_1^*\| & 0 & \ldots & 0 \\
\mu_{2,1} \|\mathbf{b}_1^*\| & \|\mathbf{b}_2^*\| & \ldots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
\mu_{d,1} \|\mathbf{b}_1^*\| & \mu_{d,2} \|\mathbf{b}_2^*\| & \ldots & \|\mathbf{b}_d^*\|
\end{pmatrix}
$$<p>Thus, $B = \mu B^{*}$ [<a id="cite-7" class="hugo-simplecite-cite-hyperlink" href="#bibreference-7" title="N. Gama and P. Nguyen, Predicting lattice reduction, In Proc. Advances in cryptology–EUROCRYPT 2008: 27th annual international conference on the theory and applications of cryptographic techniques, istanbul, turkey, april 13-17, 2008. Proceedings 27, 2008, pp. 31–51. ">7</a>][<a id="cite-1" class="hugo-simplecite-cite-hyperlink" href="#bibreference-1" title="P. Nguyen, Hermite’s constant and lattice algorithms, in The LLL algorithm: Survey and applications, Springer, 2009, pp. 19–69.">1</a>]. We can confirm from this matrix that $\text{Vol}(\Lambda) = \prod_{i=1}^{d} \lVert \bold{b}_i^* \rVert$ (the determinant is the product of the diagonal elements).</p>
<p>We can also state the following lemma that relates the shortest vector to the Gram-Schmidt vectors for all $1 \leq i \leq d$:</p>
$$
\lambda_i(\Lambda) \geq \min_{i \leq j \leq d} \|\mathbf{b}_j^*\|.
$$<p><em>Remember that the volume is an invariant, so not all Gram-Schmidt vectors can be small at the same time.</em></p>
<h3 id="root-hermite-factor">
  Root hermite factor
  <a class="anchor" href="#root-hermite-factor">#</a>
</h3>
<p>We will next want to introduce a value called the <em>root hermite factor</em>. It is a measure used in lattice reduction theory to evaluate the quality of a reduced lattice basis. It is commonly used to assess the effectiveness of lattice reduction algorithms.</p>
$$
\delta = \left( \frac{\|\mathbf{b}_1\|}{\text{vol}(\Lambda)^{1/d}} \right)^{1/d}
$$<p>
for a d-dimensional lattice.</p>
<p>The closer $\delta$ gets to 1, the better the reduction quality will be. This is of direct impact in our context, since we need to balance a trade-off between the quality of the output basis and the cost of running our lattice reduction algorithm. In fact, with the BKZ algorithm which has become the standard, a bigger block-size leads to a better quality of output basis (so a better $\delta_\beta$) but also a greater computational cost.</p>
<h3 id="geometric-series-assumption-gsa">
  Geometric Series Assumption (GSA)
  <a class="anchor" href="#geometric-series-assumption-gsa">#</a>
</h3>
<p>How large the minimas can be after lattice reduction is therefore looking for how short we expect the basis vectors to be after applying lattice reduction (which contains Gram-Schmidt orthogonalization). It is often useful to look at the length of all gram-schmidt vectors, not only the first one. As a small experiment, let us consider a basis in $\mathbb{Z}_q$ and let us compute the Gram-Schmidt orthogonalization. If we look at the log of these lengths we obtain the Z-shape because the first are orthogonal components of q magnitude and the rest are all vectors of length 1:</p>
<figure style="text-align: center; margin: 1em auto; max-width: 100%;">
    <img src="before_LLL.png" alt="Log lengths of GS vectors" style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px;">
    
        
            <figcaption style="font-size: 0.9em; margin-top: 0.5em; font-style: italic; text-align: center; color: #555;">
                Length of log GS vectors
            </figcaption>
        
    
</figure>
<p>If we now apply a lattice reduction algorithm (here LLL), we will obtain this:</p>
<figure style="text-align: center; margin: 1em auto; max-width: 100%;">
    <img src="after_LLL.png" alt="Log lengths of GS vectors after LLL" style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px;">
    
        
            <figcaption style="font-size: 0.9em; margin-top: 0.5em; font-style: italic; text-align: center; color: #555;">
                Length of vectors after LLL
            </figcaption>
        
    
</figure>
<p>You can observe this merely looks like a straight line and indeed this is the assumption that we will make. <em>The Geometric Series Assumption</em> conceptually tells us that the Gram-Schmidt vectors log-length outputed by a lattice reducion algorithm will follow a geometric series and such a line in log lengths. We can formulate it as:</p>
$$\lVert \bold{b_i}^*\rVert \approx \alpha^{i-1}\lVert \bold{b_1}\rVert$$<p>and in fact by combining it with the fact that output vector of lattice reduction follow $\lVert \bold{b_0} \rVert = \delta_0 Vol(\Lambda)^{\frac{1}{d}}$ we can get a relation between the quality of the reduction and the slope of the GSA assumption as $\alpha \approx \delta^{-2}$ leading to</p>
$$ \lVert \bold{b_i}^*\rVert \approx \alpha^{i-1} \delta^d Vol(\Lambda)^\frac{1}{d} = \delta^{-1(i+1) + d} Vol(\Lambda)^\frac{1}{d}$$<h2 id="lll-algorithm">
  LLL algorithm
  <a class="anchor" href="#lll-algorithm">#</a>
</h2>
<p>The Lenstra-Lenstra-Lovász (LLL) algorithm is an efficient polynomial-time algorithm that finds a &ldquo;nearly orthogonal&rdquo; basis for a given lattice. It aims to transform any arbitrary basis of a lattice into a reduced basis where the basis vectors are short and close to orthogonal following two conditions:</p>
<ol>
<li>Size reduction:
$$1 \leq j < i \leq d\colon \left|\mu_{i,j}\right|\leq 0.5 \text{ for } \mu_{i,j} =\frac{\langle\mathbf{b}_i,\mathbf{b}^*_j\rangle}{\langle\mathbf{b}^*_j,\mathbf{b}^*_j\rangle}$$</li>
<li>Lovász condition:
For $k=2,&hellip;,d$ $$\omega \Vert \mathbf{b}^*_{k-1}\Vert^2  \leq \Vert \mathbf{b}^*_k\Vert^2+ \mu_{k,k-1}^2\Vert\mathbf{b}^*_{k-1}\Vert^2$$</li>
</ol>
<p>We say the basis is LLL-reduced if there exists a parameter $\omega \in (0.25, 1)$. Hereafter we give a pseudo code of the algorithm and a graphical example of its run.</p>
<pre><code>  Data: a basis B
  Repeat until no changes:
     for k = 0 to d-1:
        # Step 1: Gram-Schmidt Orthogonalization (GSO)
        for i = k+1 to d-1:
              mu[k, i] = &lt;B[k], B[i]&gt; / &lt;B[k], B[k]&gt;
              B[i] = B[i] - mu[k, i] * B[k] 
        
        # Step 2: Size Reduction
        for i = k+1 to d-1:
              if |mu[k, i]| &gt;= 1/2:
                 v = round(mu[k, i])  
                 B[i] = B[i] - v * B[k]  

        # Step 3: Swap if necessary
        if &lt;B[k+1], B[k+1]&gt; &lt; (delta * &lt;B[k], B[k]&gt;):
              Swap B[k], B[k+1]

  end
</code></pre>
<figure style="text-align: center;">
    <iframe 
        src="https://xavmarch13.github.io/lattirust_estimator.io/graphs/lll.html" 
        width="100%" 
        height="600" 
        title="My Graph" 
        style="ZgotmplZ">
    </iframe>
    
    <figcaption style="font-style: italic; margin-top: 8px;">
        Example of the LLL algorithm running.
    </figcaption>
    
</figure>
<p>Although there are theorems bounding the worst-case performance of lattice reduction algorithms, they tend to perform better in practice. Reasoning about the behavior of such algorithms has therefore become a matter of heuristics and approximations. Typically, the vectors that are output by the LLL algorithm are said to follow the geometric series assumption in their length. Again, this assumption tells us that the shape after lattice reduction forms a line with a flatter slope as the reduction becomes stronger. The goal of a lattice reduction algorithm can therefore be visualized by examining a plot of the log-length of vectors after reductions. The overall goal is to flatten this line, leading to a smaller basis.</p>
<h3 id="cost-of-lll">
  Cost of LLL
  <a class="anchor" href="#cost-of-lll">#</a>
</h3>
<p>The theoretical bound on the quality of the LLL is $\delta^d = (\frac{4}{3})^\frac{d-1}{4}$ [<a id="cite-1" class="hugo-simplecite-cite-hyperlink" href="#bibreference-1" title="P. Nguyen, Hermite’s constant and lattice algorithms, in The LLL algorithm: Survey and applications, Springer, 2009, pp. 19–69.">1</a>] leading to approximately $\delta \approx 1.075$. In practice, we get much better results on average, empirically about $\delta \approx 1.021$ .</p>
<p>In terms of runtime, we will consider a heuristic bound (which better approximates empirical results) of $O(d^3 \log^2(B))$.</p>
<h2 id="bkz-algorithm">
  BKZ algorithm
  <a class="anchor" href="#bkz-algorithm">#</a>
</h2>
<p>The Block Korkine-Zolotarev (BKZ) algorithm is a lattice reduction algorithm that generalizes the LLL algorithm to achieve stronger reduction properties. The BKZ algorithm is defined as a blockwise reduction algorithm that iteratively applies a form of lattice basis reduction to overlapping blocks of vectors within the basis. The assumption made in its analysis is that iterative blocks taken behaves like a random lattice. It is in fact a relaxation of the Hermite-Korkine-Zolotarev (HKZ) reduction. The HKZ reduction is a stronger form of lattice reduction that ensures each vector in the basis is the shortest vector in the lattice projected orthogonally onto the space spanned by the preceding basis vectors.</p>
<h3 id="hkz-reduction">
  HKZ reduction
  <a class="anchor" href="#hkz-reduction">#</a>
</h3>
<p>Let <strong>b</strong>₁, <strong>b</strong>₂, &hellip;, <strong>b</strong>ₙ be a basis of a lattice <strong>L</strong>.<br>
The basis is said to be HKZ-reduced if:</p>
<ol>
<li><strong>b</strong>₁ is the shortest vector in the lattice <strong>L</strong>.</li>
<li>For <em>i</em> = 2, 3, &hellip;, <em>n</em>, the vector <strong>b</strong>ᵢ is the shortest vector in the lattice <strong>L</strong> projected orthogonally onto the span of <strong>b</strong>₁, <strong>b</strong>₂, &hellip;, <strong>b</strong>ᵢ₋₁.</li>
</ol>
<h3 id="bkz">
  BKZ
  <a class="anchor" href="#bkz">#</a>
</h3>
<p>Assuming we have an SVP oracle, the BKZ algorithm is defined as follows:</p>
<pre><code>Data: LLL-reduced basis B (preprocessed) and block size beta
repeat until no changes
    for k in 0 to d-2
        LLL on local projected block B[k, ..., min(k+beta, d)]
        v &lt;-- SVP-Oracle(local projected block B[k, ..., min(k+beta, d)])
        insert v into B at index k and handle linear dependencies with LLL
    end
</code></pre>
<p>In practice, stronger preprocessing than LLL is often performed before the BKZ block loop. Hereafter is a simple representation of a block moving through a matrix for one tour of BKZ, in practice we often do several tours because we are supposed to stop when no more significant changes occur.</p>
<figure style="text-align: center;">
    <iframe 
        src="https://xavmarch13.github.io/lattirust_estimator.io/graphs/bkz.html" 
        width="100%" 
        height="500" 
        title="Interactive Graph" 
        style="ZgotmplZ">
    </iframe>
    
    <figcaption style="font-style: italic; margin-top: 8px;">
        Example of the BKZ algorithm block sliding.
    </figcaption>
    
</figure>
<p>Theoretically, a BKZ-$\beta$ reduced basis satisfies, for $\epsilon &gt; 0$:</p>
$$\lVert \bold{b_0} \rVert \leq \sqrt{(1 + \epsilon) \gamma_{\beta}}^{(\frac{d-1}{\beta - 1} + 1)} Vol(\Lambda(\bold{B}))$$$$\gamma_\beta =  \sup \{ \lambda_1(\Lambda) | \Lambda \in \mathbb{R}^\beta, Vol(\Lambda) = 1 \}$$<p>Several variants of BKZ exist, the one giving asymptotically the best worst-case guarantees is the Slide reduction described in [<a id="cite-8" class="hugo-simplecite-cite-hyperlink" href="#bibreference-8" title="N. Gama and P. Nguyen, Finding short lattice vectors within mordell’s inequality, In Proc. Proceedings of the fortieth annual ACM symposium on theory of computing, 2008, pp. 207–216. ">8</a>] and it achieves</p>
$$\lVert \bold{b_0} \rVert \leq \sqrt{(1 + \epsilon) \gamma_{\beta}}^\frac{d-1}{\beta - 1} Vol(\Lambda(\bold{B}))$$<p>By combining the gaussian heuristic and the definition of a BKZ-$\beta$ reduced basis, we arrive again at the geometric assumption, which states that the log-lengths of reduced vectors follow a geometric series (which we can plot as a line as we did for LLL). This time however, it depends on the block-size chosen to run BKZ.</p>
<p>We can write</p>
$$\log(\lVert \bold{b_i}^*\rVert) = \frac{d - 1 - 2i}{2}\log(\alpha_\beta) + \frac{1}{d}\log(Vol(\Lambda))$$<p>where $\alpha_\beta$ is the slope under the geometric assumption that can be calculated from the gaussian assumption as</p>
$$\alpha_\beta = \sqrt{\frac{d}{2\pi e}}^\frac{2}{\beta - 1}$$<p>This result from [<a id="cite-6" class="hugo-simplecite-cite-hyperlink" href="#bibreference-6" title="M. Albrecht and L. Ducas, Lattice attacks on NTRU and LWE: A history of refinements, Cryptology ePrint Archive, 2021. ">6</a>] is reasonably accurate only if $d\gg\beta$ and $\beta &gt; 50$, which is why we will use fixed estimates for small dimensions (also, small dimension can be directly solved by an exact solver).</p>
<h3 id="cost-of-bkz">
  Cost of BKZ
  <a class="anchor" href="#cost-of-bkz">#</a>
</h3>
<ul>
<li>Costing BKZ means having a good idea of the impact of the block-size on the quality of our reduced basis. For this, we could either make the approximation $\delta_\beta \approx \sqrt \alpha_\beta$ or use the following limit defined in [<a id="cite-9" class="hugo-simplecite-cite-hyperlink" href="#bibreference-9" title="Y. Chen, Reduction de reseau et securite concrete du chiffrement completement homomorphe. Paris 7, 2013. ">9</a>] that works well for $\beta &gt; 50$ and typical $d$ used in cryptography [<a id="cite-6" class="hugo-simplecite-cite-hyperlink" href="#bibreference-6" title="M. Albrecht and L. Ducas, Lattice attacks on NTRU and LWE: A history of refinements, Cryptology ePrint Archive, 2021. ">6</a>].</li>
</ul>
$$\lim_{\beta\rightarrow\infty}\delta_\beta = (\frac{\beta}{2\pi e}(\pi\beta)^\frac{1}{\beta})^\frac{1}{2(\beta - 1)}$$<p>and write for SIS</p>
$$\lVert \bold{b_1} \rVert \approx \delta_\beta^{d-1} Vol(\Lambda)^{\frac{1}{d}}$$<ul>
<li>Costing BKZ as a whole is complicated because we do not know how many tours we will have to run, which means we don&rsquo;t really know in advance the number of SVP-Oracle calls we will have to make. Furthermore, many improvements on plain BKZ have been made when some techniques are used as a subroutine for the oracle (for example extreme pruning in the context of enumeration), which makes security estimates done via lattice reduction very sensitive to many factors. Also, local preprocessing techniques have been introduced as part of the algorithm in a variant of BKZ known as progressive BKZ. To make our tool comparable to the lattice estimator by [<a id="cite-10" class="hugo-simplecite-cite-hyperlink" href="#bibreference-10" title="M. Albrecht, R. Player, and S. Scott, On the concrete hardness of learning with errors. Cryptology ePrint Archive, Paper 2015/046, 2015. [Online]. Available: https://eprint.iacr.org/2015/046  ">10</a>], we will follow the same simplifying assumption and consider a consistent 8 tours of BKZ. This makes sense following experimental results that showed that most progress is made in the 7-9 first tours. We will then use:
$$cost = \tau \cdot d \cdot T_{SVP}$$
where</li>
</ul>
<ol>
<li>the number of BKZ tours we do $\tau$ is considered to be 8.</li>
<li>The number of times the SVP oracle is called per tour, which is about the dimension of the lattice d</li>
<li>The cost of the SVP oracle is $T_{SVP}$</li>
</ol>
<h2 id="refinements">
  Refinements
  <a class="anchor" href="#refinements">#</a>
</h2>
<p>A good history of the refinements that have been made about BKZ runtime and the way we assume security in problems based on lattice reduction can be found in [<a id="cite-6" class="hugo-simplecite-cite-hyperlink" href="#bibreference-6" title="M. Albrecht and L. Ducas, Lattice attacks on NTRU and LWE: A history of refinements, Cryptology ePrint Archive, 2021. ">6</a>]. Indeed, it appears some of our assumptions are not entirelly true, especially GSA. In the estimator, most refinements are either directly modelled into a new simulator for the GSA shape or through adjusted cost models of SVP oracles. The way we cost BKZ as a whole stays the same.</p>
<h3 id="the-first-gsa-lie">
  The first GSA lie
  <a class="anchor" href="#the-first-gsa-lie">#</a>
</h3>
<p>If we think more about the way we slide the block through the matrix during lattice reduction, we can easily come to the conclusion that something different must happen at the end. Indeed, the GSA assumptions ignores what happens for the last $d-\beta$ coordinates. This last block is in fact HKZ reduced and we can therefore adapt the tail of our assumption leading to Tail-adapted GSA (TGSA).</p>
<p>Let us use the following definition for the HKZ-shape in dimension d. For $i=0, \ldots , d-1:$</p>
$$
h_i = \log\left(\sqrt{\frac{d - i}{2\pi e}}\right) - \frac{1}{d-1} \sum_{j < i} h_j,
$$<p>Now using this in modifying our BKZ GSA assumed shape we can get the following two parts equation:</p>
$$
\log\left(\|b_i^*\|\right) =
\begin{cases} 
\frac{d - 1 - 2i}{2} \log(\alpha \beta) + s, & \text{for } 0 \leq i \leq d - \beta, \\
h_{i-(d-\beta)} + \log\left(\|b_{d-\beta}^*\|\right) - h_0, & \text{for } d-\beta \leq i < d.
\end{cases}
$$<h3 id="the-second-gsa-lie-and-ztgsa">
  The second GSA lie and Z(T)GSA
  <a class="anchor" href="#the-second-gsa-lie-and-ztgsa">#</a>
</h3>
<p>Geometric series assumptions (tail-adapted or not) have been shown to be a bad choice for small dimensions (think 50 and below) and when $d$ is a multiple of $\beta$. Furthermore, these assumptions only give an estimate about the size after the algorithm is finished and not the evolution of vectors through it. We will here just mention that an estimator has been introduced in [<a id="cite-3" class="hugo-simplecite-cite-hyperlink" href="#bibreference-3" title="Y. Chen and P. Nguyen, BKZ 2.0: Better lattice security estimates, In Proc. International conference on the theory and application of cryptology and information security, 2011, pp. 1–20. ">3</a>] to take these observations into accounts. Thanks to its implementation in FPyLLL, we will make use of it to calculate the cost of BKZ for small values (by simply hardcoding the needed values).</p>
<p>Because we will work with q-ary lattices,  they will always contain vector $(q, 0, \ldots, 0)$ and its permutation. These vectors can be considered short in certain circonstances and shorter that what GSA would predict. A ZGSA assumption adapted to such lattices is possible, but it remains unsure what such an assumption would look like on block reduction algorithms.</p>
<h3 id="bkz-20-improvements">
  BKZ 2.0 improvements
  <a class="anchor" href="#bkz-20-improvements">#</a>
</h3>
<p>BKZ 2.0 [<a id="cite-3" class="hugo-simplecite-cite-hyperlink" href="#bibreference-3" title="Y. Chen and P. Nguyen, BKZ 2.0: Better lattice security estimates, In Proc. International conference on the theory and application of cryptology and information security, 2011, pp. 1–20. ">3</a>]  introduces several enhancements to the traditional BKZ algorithm, improving its efficiency and the quality of lattice reduction. Here, we summarize the key improvements:</p>
<ul>
<li>
<p><strong>Introduction of Pruning</strong>:</p>
<ul>
<li>BKZ 2.0 incorporates <strong>sound pruning</strong> and <strong>extreme pruning</strong>, techniques introduced by Gama, Nguyen, and Regev.</li>
<li>These pruning methods reduce the size of the enumeration tree by removing branches with negligible probability of success.</li>
</ul>
</li>
<li>
<p><strong>Preprocessing of Local Blocks</strong>:</p>
<ul>
<li>BKZ 2.0 ensures local bases are better reduced than standard LLL-reduction before enumeration.</li>
<li>This preprocessing step reduces the cost of enumeration by improving the quality of the local basis.</li>
<li>For a local projected lattice \( L[j,k] \), preprocessing increases the volumes of projected lattices \( L[k-d+1,k] \), reducing the size of the enumeration tree.</li>
</ul>
</li>
<li>
<p><strong>Optimizing the Enumeration Radius</strong>:</p>
<ul>
<li>BKZ 2.0 optimizes the initial radius \( R \) for enumeration to avoid unnecessary computation.</li>
<li>The optimized radius is calculated as:
$$
    R = \min\left(\sqrt{\gamma} \cdot \text{GH}(L[j,k]), \|b_j^*\|\right),
    $$
where \( \text{GH}(L[j,k]) \) is the Gaussian heuristic for the local block and \( \gamma \approx 1.1 \).</li>
</ul>
</li>
<li>
<p><strong>Simulation for High Block Sizes</strong>:</p>
<ul>
<li>BKZ 2.0 predicts output quality and running time for high block sizes (\( \beta \geq 50 \)) through a simulation algorithm.</li>
<li>This includes:
<ol>
<li>Predicting the Gram-Schmidt sequence \( \|b_i^*\| \) during BKZ 2.0 reduction.</li>
<li>Estimating the block sizes required to achieve a target Hermite factor.</li>
</ol>
</li>
</ul>
</li>
</ul>
<h1 id="references">
  References
  <a class="anchor" href="#references">#</a>
</h1>
<ol class="hugo-simplecite-reference-list"><li class="hugo-simplecite-reference-list-item" id="bibreference-1">P. Nguyen,&#32;<q>Hermite’s constant and lattice algorithms,</q>&#32;in <em>The LLL algorithm: Survey and applications</em>,&#32;Springer, 2009, pp. 19–69.<a href="#cite-1" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-2">P. Nguyen and&#32;B. Vallee,&#32;<em>The LLL algorithm</em>.&#32;Springer, 2010.&#32;<a href="#cite-2" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-3">Y. Chen and&#32;P. Nguyen,&#32;<q>BKZ 2.0: Better lattice security estimates,</q>&#32;In Proc. International conference on the theory and application of cryptology and information security,&#32;2011, pp. 1–20.&#32;<a href="#cite-3" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-4">N. Gama,&#32;N. Howgrave-Graham,&#32;H. Koy, and&#32;P. Nguyen,&#32;<q>Rankin’s constant and blockwise lattice reduction,</q>&#32;In Proc. Advances in cryptology-CRYPTO 2006: 26th annual international cryptology conference, santa barbara, california, USA, august 20-24, 2006. Proceedings 26,&#32;2006, pp. 112–130.&#32;<a href="#cite-4" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-5">A. Lenstra,&#32;H. Lenstra, and&#32;L. Lovász,&#32;<q>Factoring polynomials with rational coefficients,</q>&#32;<em>Mathematische annalen</em>,&#32;vol. 261,&#32;pp. 515–534,&#32;1982.&#32;<a href="#cite-5" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-6">M. Albrecht and&#32;L. Ducas,&#32;<q>Lattice attacks on NTRU and LWE: A history of refinements,</q>&#32;<em>Cryptology ePrint Archive</em>,&#32;2021.&#32;<a href="#cite-6" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-7">N. Gama and&#32;P. Nguyen,&#32;<q>Predicting lattice reduction,</q>&#32;In Proc. Advances in cryptology–EUROCRYPT 2008: 27th annual international conference on the theory and applications of cryptographic techniques, istanbul, turkey, april 13-17, 2008. Proceedings 27,&#32;2008, pp. 31–51.&#32;<a href="#cite-7" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-8">N. Gama and&#32;P. Nguyen,&#32;<q>Finding short lattice vectors within mordell’s inequality,</q>&#32;In Proc. Proceedings of the fortieth annual ACM symposium on theory of computing,&#32;2008, pp. 207–216.&#32;<a href="#cite-8" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-9">Y. Chen,&#32;<em>Reduction de reseau et securite concrete du chiffrement completement homomorphe</em>.&#32;Paris 7, 2013.&#32;<a href="#cite-9" class="back-arrow" title="Back to text">↩</a></li><li class="hugo-simplecite-reference-list-item" id="bibreference-10">M. Albrecht,&#32;R. Player, and&#32;S. Scott,&#32;<em>On the concrete hardness of learning with errors</em>.&#32;Cryptology ePrint Archive, Paper 2015/046, 2015.&#32;[Online]. Available: <a class="hugo-simplecite-url-hyperlink" rel="noopener" target="_blank" href="https://eprint.iacr.org/2015/046">https://eprint.iacr.org/2015/046</a>&#32;
<a href="#cite-10" class="back-arrow" title="Back to text">↩</a></li></ol>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#lattice-reduction">Lattice reduction</a>
      <ul>
        <li><a href="#key-lattice-reduction-algorithms">Key Lattice Reduction Algorithms</a></li>
        <li><a href="#cost-considerations">Cost Considerations</a></li>
        <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization</a></li>
        <li><a href="#root-hermite-factor">Root hermite factor</a></li>
        <li><a href="#geometric-series-assumption-gsa">Geometric Series Assumption (GSA)</a></li>
      </ul>
    </li>
    <li><a href="#lll-algorithm">LLL algorithm</a>
      <ul>
        <li><a href="#cost-of-lll">Cost of LLL</a></li>
      </ul>
    </li>
    <li><a href="#bkz-algorithm">BKZ algorithm</a>
      <ul>
        <li><a href="#hkz-reduction">HKZ reduction</a></li>
        <li><a href="#bkz">BKZ</a></li>
        <li><a href="#cost-of-bkz">Cost of BKZ</a></li>
      </ul>
    </li>
    <li><a href="#refinements">Refinements</a>
      <ul>
        <li><a href="#the-first-gsa-lie">The first GSA lie</a></li>
        <li><a href="#the-second-gsa-lie-and-ztgsa">The second GSA lie and Z(T)GSA</a></li>
        <li><a href="#bkz-20-improvements">BKZ 2.0 improvements</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












